{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# ChebGCNs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Spectral Graph ConvNets<br>\n",
    "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering<br>\n",
    "M Defferrard, X Bresson, P Vandergheynst<br>\n",
    "Advances in Neural Information Processing Systems, 3844-3852, 2016<br>\n",
    "ArXiv preprint: [arXiv:1606.09375](https://arxiv.org/pdf/1606.09375.pdf) <br>\n",
    "\n",
    "DOC : https://docs.dgl.ai/en/latest/api/python/nn.pytorch.html?highlight=cheb#dgl.nn.pytorch.conv.ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import rescale_L\n",
    "\n",
    "#import collections\n",
    "# MAC PROBLEM THAT MAKES THE NOTEBOOK Crash\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "sys.path.insert(0, 'lib/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n"
     ]
    }
   ],
   "source": [
    "# GPU Compatibility\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "    dtypeFloat = torch.cuda.FloatTensor\n",
    "    dtypeLong = torch.cuda.LongTensor\n",
    "    torch.cuda.manual_seed(1)\n",
    "    device=torch.device('cuda:0')\n",
    "else:\n",
    "    print('cuda not available')\n",
    "    dtypeFloat = torch.FloatTensor\n",
    "    dtypeLong = torch.LongTensor\n",
    "    torch.manual_seed(1)\n",
    "    device=torch.device('cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Downloads the dataset if not found locally\n",
    "from utils import check_mnist_dataset_exists\n",
    "_ = check_mnist_dataset_exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 784]) <class 'torch.Tensor'>\n",
      "torch.Size([512])\n",
      "torch.Size([128, 784])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "nb_selected_train_data = 512\n",
    "nb_selected_test_data = 128\n",
    "\n",
    "train_data = torch.load('mnist/train_data.pt').reshape(60000, 784)\n",
    "train_data = train_data[:nb_selected_train_data, :]\n",
    "print(train_data.shape, type(train_data))\n",
    "\n",
    "train_labels = torch.load('mnist/train_label.pt')\n",
    "train_labels = train_labels[:nb_selected_train_data]\n",
    "print(train_labels.shape)\n",
    "\n",
    "test_data = torch.load('mnist/test_data.pt').reshape(10000, 784)\n",
    "test_data = test_data[:nb_selected_test_data, :]\n",
    "print(test_data.shape)\n",
    "\n",
    "test_labels = torch.load('mnist/test_label.pt')\n",
    "test_labels = test_labels[:nb_selected_test_data]\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Import the dataset from file\n",
    "from Dataset import MNISTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainset = MNISTDataset(train_data,train_labels)\n",
    "testset = MNISTDataset(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Convolution layer and classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from model import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Debug section\n",
    "Verifying all of the steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "g, l = collate((trainset[0], trainset[1]))\n",
    "net = Classifier(1,200,trainset.num_classes,k=5).to(torch.device('cuda:0'))\n",
    "print(\"-------------------- Network model --------------------\\n\", net)\n",
    "\n",
    "t = time.time()\n",
    "## Calculate L \n",
    "g.to(torch.device('cuda:0')) \n",
    "L,lmax = laplacian(g)\n",
    "L = rescale_L(L).to(torch.device('cuda:0')) \n",
    "print('L',L,'size:',len(L),'time',time.time()-t,L.dtype)\n",
    "print('Lmax',lmax,len(lmax))\n",
    "\n",
    "\n",
    "print(\"\\n --------------------  Output for graph g:  --------------------\\n\", net(g,L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "L,lmax = laplacian(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model definition for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (layers): ModuleList(\n",
      "    (0): Chebyconv(\n",
      "      (apply_mod): NodeApplyModule(\n",
      "        (linear): Linear(in_features=15, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Chebyconv(\n",
      "      (apply_mod): NodeApplyModule(\n",
      "        (linear): Linear(in_features=480, out_features=200, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classify): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=50, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Classifier(1, 200, trainset.num_classes,k=15)\n",
    "print(net)\n",
    "if torch.cuda.is_available():\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Reference : \n",
    "\n",
    "Graph ConvNet: LeNet5\n",
    "nb of parameters= 1663370 \n",
    "\n",
    "Graph_ConvNet_LeNet5(\n",
    "  (cl1): Linear(in_features=25, out_features=32, bias=True)\n",
    "  (cl2): Linear(in_features=800, out_features=64, bias=True)\n",
    "  (fc1): Linear(in_features=3136, out_features=512, bias=True)\n",
    "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
    ")\n",
    "\n",
    "With original parameters: \n",
    "D = train_data.shape[1]\n",
    "CL1_F = 32\n",
    "CL1_K = 25\n",
    "CL2_F = 64\n",
    "CL2_K = 25\n",
    "FC1_F = 512\n",
    "FC2_F = 10\n",
    "net_parameters = [D, CL1_F, CL1_K, CL2_F, CL2_K, FC1_F, FC2_F]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Training pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Use PyTorch's DataLoader and the collate function\n",
    "# defined before.\n",
    "data_loader = DataLoader(trainset, batch_size=64,\n",
    "                         shuffle=True, collate_fn=collate)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
      "  warnings.warn(msg, warn_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction time: 0.9629108905792236\n",
      "optimizer time: 0.3984506130218506\n",
      "Epoch 0, loss 2.3491, in 9.52(s) \n",
      "prediction time: 0.39241671562194824\n",
      "optimizer time: 0.4250810146331787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dfe2516ba706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optimizer time:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DGL/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DGL/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "net.train()\n",
    "from utils import laplacian\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# This line is way too long computationally! ----------------------\n",
    "        \n",
    "for epoch in range(20):\n",
    "    epoch_loss = 0\n",
    "    t0 = time.time()\n",
    "    for iter, (bg, label) in enumerate(data_loader):\n",
    "        if (iter == 0): \n",
    "            L , lmax = laplacian(bg)\n",
    "            L = rescale_L(L).to(torch.device('cuda:0')) \n",
    "        if torch.cuda.is_available():\n",
    "            bg.to(device) # torch.device('cuda:0')\n",
    "        if (iter == 0): t = time.time()\n",
    "        prediction = net(bg,L)\n",
    "        if (iter == 0): print('prediction time:',time.time()-t )\n",
    "        if (iter == 0): t = time.time()\n",
    "        # print(\"Prediction:\", prediction,'len:',prediction.size())  #DEBUG\n",
    "        loss = loss_func(prediction, label.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if (iter == 0): print('optimizer time:',time.time()-t )\n",
    "        if (iter == 0): t = time.time()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    print('Epoch {}, loss {:.4f}, in {:.2f}(s) '.format(\n",
    "        epoch, epoch_loss, time.time()-t0))\n",
    "    epoch_losses.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('cross entropy averaged over minibatches')\n",
    "plt.plot(epoch_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of utils failed: Traceback (most recent call last):\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "RecursionError: maximum recursion depth exceeded while calling a Python object\n",
      "]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 37.52 GiB (GPU 0; 10.92 GiB total capacity; 44.00 MiB already allocated; 10.28 GiB free; 68.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-68df8f96cbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m L= rescale_L(torch.from_numpy(nx.normalized_laplacian_matrix(\n\u001b[0;32m---> 12\u001b[0;31m     test_bg.to_networkx().to_undirected()).todense()).float()).to(torch.device('cuda:0')) # This operation takes 3 seconds\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprobs_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 37.52 GiB (GPU 0; 10.92 GiB total capacity; 44.00 MiB already allocated; 10.28 GiB free; 68.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# BATCHED DGL EXAMPLE\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "# Change \n",
    "\n",
    "net.eval()\n",
    "# Convert a list of tuples to two lists\n",
    "test_X, test_Y = map(list, zip(*testset))\n",
    "test_bg = dgl.batch(test_X).to(torch.device('cuda:0'))\n",
    "test_Y = torch.tensor(test_Y).float().view(-1, 1)\n",
    "L= rescale_L(torch.from_numpy(nx.normalized_laplacian_matrix(\n",
    "    test_bg.to_networkx().to_undirected()).todense()).float()).to(torch.device('cuda:0')) # This operation takes 3 seconds\n",
    "\n",
    "probs_Y = torch.softmax(net(test_bg,L), 1)\n",
    "sampled_Y = torch.multinomial(probs_Y, 1)\n",
    "argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n",
    "\n",
    "#sklearn.metrics.classification_report(test_Y,argmax_Y)\n",
    "\n",
    "print('Accuracy of sampled predictions on the test set: {:.4f}%'.format(\n",
    "    (test_Y == sampled_Y.float()).sum().item() / len(test_Y) * 100))\n",
    "print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
    "    (test_Y == argmax_Y.float()).sum().item() / len(test_Y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of utils failed: Traceback (most recent call last):\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/axel/miniconda3/envs/DGL/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "RecursionError: maximum recursion depth exceeded while calling a Python object\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from utils import save_model\n",
    "save_model('Model1', net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "$h_i^{l+1}$ &= $\\sum_{k=0}^{K-1} W^{k, l}z_i^{k, l}$\n",
    "\n",
    "$Z^{0, l}$ &= $H^{l}$\n",
    "\n",
    "$Z^{1, l}$ &=$ \\hat{L} \\cdot H^{l}$\n",
    "\n",
    "$Z^{k, l}$ &= $2 \\cdot \\hat{L} \\cdot Z^{k-1, l} - Z^{k-2, l}$\n",
    "\n",
    "$\\hat{L}$ &= $2\\left(I - \\hat{D}^{-1/2} \\hat{A} \\hat{D}^{-1/2}\\right)/\\lambda_{max} - I$\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feats: int\n",
    "        Number of input features.\n",
    "    out_feats: int\n",
    "        Number of output features.\n",
    "    k : int\n",
    "        Chebyshev filter size.\n",
    "    bias : bool, optional\n",
    "        If True, adds a learnable bias to the output. Default: ``True``."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Save to the master thesis folder: \n",
    "plt.savefig('../../Master-Thesis/img/Chebfilters.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
